{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>arctic warming 2 to 3 times faster than anywhe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ministry seeks input on education reform, sex ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>66-year-old 'washington post' reporter hopes h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>friends don’t understand how man not depressed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>liberal leader brian gallant prepares for thro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31716</td>\n",
       "      <td>soldier acquitted in sexual assault of subordi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31717</td>\n",
       "      <td>93% of americans admit they occasionally check...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31718</td>\n",
       "      <td>inuvik rcmp ask for help in locating man wante...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31719</td>\n",
       "      <td>12 stunning, seasonal accents for under $30! h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31720</td>\n",
       "      <td>aca enrollment highest in states that voted trump</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31721 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  label\n",
       "0      arctic warming 2 to 3 times faster than anywhe...      0\n",
       "1      ministry seeks input on education reform, sex ...      0\n",
       "2      66-year-old 'washington post' reporter hopes h...      1\n",
       "3         friends don’t understand how man not depressed      1\n",
       "4      liberal leader brian gallant prepares for thro...      0\n",
       "...                                                  ...    ...\n",
       "31716  soldier acquitted in sexual assault of subordi...      0\n",
       "31717  93% of americans admit they occasionally check...      1\n",
       "31718  inuvik rcmp ask for help in locating man wante...      0\n",
       "31719  12 stunning, seasonal accents for under $30! h...      0\n",
       "31720  aca enrollment highest in states that voted trump      1\n",
       "\n",
       "[31721 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# load data\n",
    "onion = pd.read_csv('onionometer/sentences/onion.txt', sep='\\n')\n",
    "real = pd.read_csv('onionometer/sentences/real.txt', sep='\\n')\n",
    "\n",
    "# label data\n",
    "onion['label'], real['label'] = 1, 0\n",
    "\n",
    "# concatenate and shuffle data\n",
    "shuffled_data = pd.concat([onion, real]).sample(frac=1).reset_index(drop=True)\n",
    "shuffled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train/test sets\n",
    "X_train = shuffled_data.loc[:25000, 'title'].values\n",
    "y_train = shuffled_data.loc[:25000, 'label'].values\n",
    "X_test = shuffled_data.loc[25001:, 'title'].values\n",
    "y_test = shuffled_data.loc[25001:, 'label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tokenizer vocabulary\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "total_headlines = np.concatenate((X_train, X_test))\n",
    "tokenizer.fit_on_texts(total_headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = max([len(h.split()) for h in total_headlines])\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode headlines as vectors of integers\n",
    "X_train_tokenized = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_tokenized = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad input data\n",
    "X_train_padded = tf.keras.preprocessing.sequence.pad_sequences(X_train_tokenized, maxlen=max_length, padding='post')\n",
    "X_test_padded = tf.keras.preprocessing.sequence.pad_sequences(X_test_tokenized, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model.\n",
    "# 100-dimensional embedding layer followed by bidirectional LSTM\n",
    "# followed by layer of 32 densely connected neurons, \n",
    "# followed by one output neuron\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, 100, input_length=max_length))\n",
    "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)))\n",
    "model.add(tf.keras.layers.Dense(32, activation='sigmoid'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = ['sgd', 'adam', 'RMSprop']\n",
    "loss_functions = ['binary_crossentropy'] # only use binary crossentropy. hinge & hinge squared requires output set to be {-1, 1}\n",
    "\n",
    "results = {'sgd': {}, 'adam': {}, 'RMSprop': {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "25001/25001 [==============================] - 399s 16ms/sample - loss: 0.6985 - acc: 0.5252\n",
      "Epoch 2/3\n",
      "25001/25001 [==============================] - 399s 16ms/sample - loss: 0.6926 - acc: 0.5252\n",
      "Epoch 3/3\n",
      "25001/25001 [==============================] - 405s 16ms/sample - loss: 0.6920 - acc: 0.5252\n",
      "6720/6720 [==============================] - 379s 56ms/sample - loss: 0.6913 - acc: 0.5304\n",
      "Epoch 1/3\n",
      "25001/25001 [==============================] - 394s 16ms/sample - loss: 0.6552 - acc: 0.6424\n",
      "Epoch 2/3\n",
      "25001/25001 [==============================] - 393s 16ms/sample - loss: 0.3477 - acc: 0.8794\n",
      "Epoch 3/3\n",
      "25001/25001 [==============================] - 395s 16ms/sample - loss: 0.1611 - acc: 0.9506\n",
      "6720/6720 [==============================] - 373s 56ms/sample - loss: 0.2338 - acc: 0.9095\n",
      "Epoch 1/3\n",
      "25001/25001 [==============================] - 399s 16ms/sample - loss: 0.1085 - acc: 0.9678\n",
      "Epoch 2/3\n",
      "25001/25001 [==============================] - 397s 16ms/sample - loss: 0.0756 - acc: 0.9786\n",
      "Epoch 3/3\n",
      "25001/25001 [==============================] - 390s 16ms/sample - loss: 0.0562 - acc: 0.9841\n",
      "6720/6720 [==============================] - 343s 51ms/sample - loss: 0.2547 - acc: 0.9097\n"
     ]
    }
   ],
   "source": [
    "for opt in optimizers:\n",
    "    for loss_fn in loss_functions:\n",
    "        model.compile(optimizer=opt, loss=loss_fn, metrics=['accuracy'])\n",
    "        model.fit(X_train_padded, y_train, batch_size=512, epochs=3)\n",
    "        eval_loss, eval_acc = model.evaluate(X_test_padded, y_test, batch_size=512)\n",
    "        results[opt][loss_fn] = [eval_acc, eval_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sgd': {'binary_crossentropy': [0.5303571, 0.6913437494209834]},\n",
       " 'adam': {'binary_crossentropy': [0.9095238, 0.2337867608737378]},\n",
       " 'RMSprop': {'binary_crossentropy': [0.9096726, 0.2546553272931349]}}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With LSTM layer: 91% accuracy\n",
    "# Without LSTM layer it was 53% accuracy :D"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
